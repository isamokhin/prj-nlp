{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Побудова бейзлайнового POS-таггера на основі pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pymorphy2 не є POS-таггером: кожне слово аналізується у відриві від контексту і тільки якщо воно є у словнику. До того ж для української мови у pymorphy2 недоступний параметр score, який визначає імовірність правильності аналізу у випадку, коли для слова є кілька різних аналізів. Тим не менш, визначення частин мови у pymorphy2 можна покращити за допомогою кількох простих правил."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Правила формувались на тренувальній вибірці україномовних Universal Dependencies, тестувались на dev+test вибірках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conllu\n",
    "import random\n",
    "from collections import OrderedDict, Counter\n",
    "import string\n",
    "import gzip\n",
    "\n",
    "from tokenize_uk import tokenize_words\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer(lang='uk')\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'uk_iu-ud-train.conllu.gz'\n",
    "with gzip.open(fname, 'rb') as f:\n",
    "    raw_train = f.read().decode()\n",
    "\n",
    "fname2 = 'uk_iu-ud-test.conllu.gz'\n",
    "with gzip.open(fname2, 'rb') as f2:\n",
    "    raw_test = f2.read().decode()\n",
    "    \n",
    "fname3 = 'uk_iu-ud-dev.conllu.gz'\n",
    "with gzip.open(fname3, 'rb') as f3:\n",
    "    raw_dev = f3.read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = conllu.parse(raw_train)\n",
    "test = conllu.parse(raw_test) + conllu.parse(raw_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найпростіший варіант - просто визначити відповіднити частин мови UD у тегах pymorphy2 (код звідси: https://github.com/vseloved/prj-nlp/blob/master/tasks/08-syntactic-parsing.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\"ADJF\": \"ADJ\", \"ADJS\": \"ADJ\", \"COMP\": \"ADJ\", \"PRTF\": \"ADJ\",\n",
    "           \"PRTS\": \"ADJ\", \"GRND\": \"VERB\", \"NUMR\": \"NUM\", \"ADVB\": \"ADV\",\n",
    "           \"NPRO\": \"PRON\", \"PNCT\": \"PUNCT\", \"PRED\": \"ADV\", \"PREP\": \"ADP\",\n",
    "           \"PRCL\": \"PART\", None: \"X\"}\n",
    "\n",
    "def normalize_pos(word):\n",
    "    if word.tag.POS == \"CONJ\":\n",
    "        if \"coord\" in word.tag:\n",
    "            return \"CCONJ\"\n",
    "        else:\n",
    "            return \"SCONJ\"\n",
    "    else:\n",
    "        return mapping.get(word.tag.POS, word.tag.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_pymorphy(corpus):\n",
    "    labels = []\n",
    "    for sent in corpus:\n",
    "        for i, w in enumerate(sent):\n",
    "            word = w['form']\n",
    "            wparsed = morph.parse(word.lower())[0]\n",
    "            pos = normalize_pos(wparsed)\n",
    "            labels.append(pos)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [w['upostag'] for sent in test for w in sent]\n",
    "pred_labels = classify_pymorphy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ADJ       0.92      0.90      0.91      2763\n",
      "        ADP       0.99      0.59      0.74      2325\n",
      "        ADV       0.69      0.61      0.65      1112\n",
      "        AUX       0.00      0.00      0.00       183\n",
      "      CCONJ       0.86      0.96      0.91       910\n",
      "        DET       0.00      0.00      0.00       905\n",
      "       INTJ       0.02      0.55      0.03        11\n",
      "       NOUN       0.80      0.95      0.87      6757\n",
      "        NUM       1.00      0.13      0.23       448\n",
      "       PART       0.46      0.74      0.57       533\n",
      "       PRON       0.36      0.68      0.47       749\n",
      "      PROPN       0.00      0.00      0.00       939\n",
      "      PUNCT       0.00      0.00      0.00      4664\n",
      "      SCONJ       0.75      0.62      0.68       436\n",
      "        SYM       0.00      0.00      0.00        19\n",
      "       VERB       0.89      0.96      0.93      2366\n",
      "          X       0.03      0.92      0.06       190\n",
      "\n",
      "avg / total       0.60      0.61      0.59     25310\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igor/Bin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.612\n"
     ]
    }
   ],
   "source": [
    "print(round(accuracy_score(true_labels, pred_labels), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для покращення результату, потрібно:\n",
    "- додати визначення знаків пунктуації (PUNCT) та особливих символів (SYM): pymorphy2 позначає їх як PNCT в тегу, але не в `word.tag.POS`;\n",
    "- додати до числівників токени, які у `word.tag` (але не `word.tag.POS`) позначені як NUMB;\n",
    "- додати визначення AUX та DET, які відсутні в pymorphy2 - просто через список слів (знайдених у тренувальній вибірці);\n",
    "- додати просте правило для визначення PROPN (наприклад, якщо іменник не на початку речення починається з великої літери);\n",
    "- додати списки поширених у тренувальній вибірці ADP, ADV тощо, з якими зараз pymorphy2 дуже плутається."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING = {\"ADJF\": \"ADJ\", \"ADJS\": \"ADJ\", \"COMP\": \"ADJ\", \"PRTF\": \"ADJ\",\n",
    "           \"PRTS\": \"ADJ\", \"GRND\": \"VERB\", \"NUMR\": \"NUM\", \"ADVB\": \"ADV\",\n",
    "           \"NPRO\": \"PRON\", \"PRED\": \"ADV\", \"PREP\": \"ADP\", \"PRCL\": \"PART\"}\n",
    "\n",
    "DET = ['інакший', 'його', 'тамтой', 'чий', 'їх', 'інш.', 'деякий', 'ввесь', 'ваш', \n",
    "     'ніякий', 'весь', 'інший', 'чийсь', 'жадний', 'другий', 'кожний', \n",
    "     'такий', 'оцей', 'скілька', 'цей', 'жодний', 'все', 'кілька', 'увесь', \n",
    "     'кожній', 'те', 'сей', 'ін.', 'отакий', 'котрий', 'усякий', 'самий', \n",
    "     'наш', 'усілякий', 'будь-який', 'сам', 'свій', 'всілякий', 'всенький', 'її', \n",
    "     'всякий', 'отой', 'небагато', 'який', 'їхній', 'той', 'якийсь', 'ин.', 'котрийсь', \n",
    "     'твій', 'мій', 'це', 'яка', 'якась', 'ця', 'якесь', 'яке', 'весь', 'самий']\n",
    "\n",
    "SYM = set('#$%§©+=×÷=<>')\n",
    "PUNCTUATION = set(string.punctuation) - SYM\n",
    "\n",
    "def detect_pos(word, upper=False):\n",
    "    \"\"\"\n",
    "    A function to detect POS of the word \n",
    "    using pymorphy2 and simple rules.\n",
    "    \"\"\"\n",
    "    if not word.tag.POS:\n",
    "        if word.word in PUNCTUATION:\n",
    "            return \"PUNCT\"\n",
    "        elif word.word in SYM:\n",
    "            return 'SYM'\n",
    "        elif 'NUMB' in word.tag:\n",
    "            return 'NUM'\n",
    "        else:\n",
    "            return \"X\"\n",
    "    elif word.tag.POS == \"CONJ\":\n",
    "        if \"coord\" in word.tag:\n",
    "            return \"CCONJ\"\n",
    "        else:\n",
    "            return \"SCONJ\"\n",
    "    elif word.normal_form in DET:\n",
    "        return 'DET'\n",
    "    elif word.normal_form in ['на', 'за', 'після']:\n",
    "        return 'ADP'\n",
    "    elif word.normal_form in ['чи', 'натомість']:\n",
    "        return 'CCONJ'\n",
    "    elif word.normal_form in ['як', 'щоб', 'щоби', 'коли', 'мов',\n",
    "                              'хоч', 'адже', 'тобто', 'ніби', 'хоча']:\n",
    "        return 'SCONJ'\n",
    "    elif word.normal_form in ['бути', 'б', 'би']:\n",
    "        return 'AUX'\n",
    "    elif word.normal_form in ['треба', 'завжди', 'потім', 'де', 'тоді', \n",
    "                              'там', 'тут', 'далі', 'тепер']:\n",
    "        return 'ADV'\n",
    "    elif 'NOUN' in word.tag and upper:\n",
    "        return 'PROPN'\n",
    "    else:\n",
    "        return MAPPING.get(word.tag.POS, word.tag.POS)\n",
    "\n",
    "def is_upper(word):\n",
    "    if word[0].isupper():\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def classify_pymorphy(corpus):\n",
    "    labels = []\n",
    "    for sent in corpus:\n",
    "        for i, w in enumerate(sent):\n",
    "            word = w['form']\n",
    "            wparsed = morph.parse(word.lower())[0]\n",
    "            if i == 0:\n",
    "                pos = detect_pos(wparsed)\n",
    "            else:\n",
    "                pos = detect_pos(wparsed, upper=is_upper(word))\n",
    "            labels.append(pos)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [w['upostag'] for sent in test for w in sent]\n",
    "pred_labels = classify_pymorphy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ADJ       0.92      0.89      0.91      2763\n",
      "        ADP       0.99      0.82      0.90      2325\n",
      "        ADV       0.87      0.69      0.77      1112\n",
      "        AUX       0.77      0.82      0.79       183\n",
      "      CCONJ       0.85      0.99      0.91       910\n",
      "        DET       0.80      0.83      0.82       905\n",
      "       INTJ       0.11      0.36      0.17        11\n",
      "       NOUN       0.89      0.90      0.90      6757\n",
      "        NUM       0.72      0.90      0.80       448\n",
      "       PART       0.73      0.69      0.71       533\n",
      "       PRON       0.79      0.56      0.66       749\n",
      "      PROPN       0.71      0.85      0.77       939\n",
      "      PUNCT       1.00      0.86      0.92      4664\n",
      "      SCONJ       0.73      0.91      0.81       436\n",
      "        SYM       0.17      0.42      0.24        19\n",
      "       VERB       0.94      0.95      0.94      2366\n",
      "          X       0.17      0.92      0.29       190\n",
      "\n",
      "avg / total       0.90      0.86      0.87     25310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864\n"
     ]
    }
   ],
   "source": [
    "print(round(accuracy_score(true_labels, pred_labels), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остання спроба: використати ВЕСУМ для розрізнення різних типів займенників - \"іменникових\" (вони будуть PRON), \"прислівникових\" (вони, як правило, стають ADV) та \"числівникових\" і \"прикметникових\" (ці будуть DET). Для цього спершу витягнемо всі займенники зі словника разом із їхньою функціональною частиною мови, відповідним чином розфасуємо, а потім виділимо серед них тільки недвозначні (ті, для яких pymorphy2 має лише один варіант аналізу)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1754"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pron_dict = {}\n",
    "with open('/mnt/hdd/Data/NLP/dict_corp_vis.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip(' \\n')\n",
    "        word, tag = line.split()[:2]\n",
    "        if '&pron' in tag:\n",
    "            if (word in pron_dict.keys()\n",
    "                and not pron_dict[word][1] == tag.split('&')[0].split(':')[0]):\n",
    "                pron_dict[word] = 'AMBIGOUS'\n",
    "                continue\n",
    "            tagparts = tag.split('&')\n",
    "            if tagparts[0].startswith('noun'):\n",
    "                pron_dict[word] = ('PRON', 'noun')\n",
    "            elif tagparts[0].startswith('adv'):\n",
    "                pron_dict[word] = ('ADV', 'noun')\n",
    "            elif tagparts[0].startswith('numr'):\n",
    "                pron_dict[word] = ('DET', 'numr')\n",
    "            elif tagparts[0].startswith('adj'):\n",
    "                pron_dict[word] = ('DET', 'adj')\n",
    "len(pron_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "697"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disamb_dict = {}\n",
    "for k,v in pron_dict.items():\n",
    "    if v == 'AMBIGOUS':\n",
    "        continue\n",
    "    elif len(morph.parse(k)) > 1:\n",
    "        if len(set(word.tag.POS for word in morph.parse(k))) > 1:\n",
    "            continue\n",
    "    else:\n",
    "        disamb_dict[k] = pron_dict[k][0]\n",
    "len(disamb_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_pymorphy2(corpus):\n",
    "    labels = []\n",
    "    for sent in corpus:\n",
    "        for i, w in enumerate(sent):\n",
    "            word = w['form']\n",
    "            wparsed = morph.parse(word.lower())[0]\n",
    "            if word in disamb_dict.keys():\n",
    "                pos = disamb_dict[word]\n",
    "            elif i == 0:\n",
    "                pos = detect_pos(wparsed)\n",
    "            else:\n",
    "                pos = detect_pos(wparsed, upper=is_upper(word))\n",
    "            labels.append(str(pos))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ADJ       0.92      0.89      0.91      2763\n",
      "        ADP       0.99      0.82      0.90      2325\n",
      "        ADV       0.87      0.71      0.78      1112\n",
      "        AUX       0.77      0.82      0.79       183\n",
      "      CCONJ       0.85      0.99      0.91       910\n",
      "        DET       0.80      0.83      0.82       905\n",
      "       INTJ       0.11      0.36      0.17        11\n",
      "       NOUN       0.89      0.90      0.90      6757\n",
      "        NUM       0.72      0.90      0.80       448\n",
      "       PART       0.73      0.69      0.71       533\n",
      "       PRON       0.82      0.56      0.67       749\n",
      "      PROPN       0.71      0.85      0.77       939\n",
      "      PUNCT       1.00      0.86      0.92      4664\n",
      "      SCONJ       0.73      0.91      0.81       436\n",
      "        SYM       0.17      0.42      0.24        19\n",
      "       VERB       0.94      0.95      0.94      2366\n",
      "          X       0.17      0.92      0.29       190\n",
      "\n",
      "avg / total       0.90      0.86      0.87     25310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_labels = [w['upostag'] for sent in test for w in sent]\n",
    "pred_labels = classify_pymorphy2(test)\n",
    "print(classification_report(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864\n"
     ]
    }
   ],
   "source": [
    "print(round(accuracy_score(true_labels, pred_labels), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888\n"
     ]
    }
   ],
   "source": [
    "def combine_tags(tag_list):\n",
    "    mapping = {'DET': 'PRON', 'SYM': 'PUNCT', \n",
    "               'AUX': 'VERB', 'PROPN': 'NOUN'}\n",
    "    return [mapping.get(tag, tag) for tag in tag_list]\n",
    "\n",
    "print(round(accuracy_score(combine_tags(true_labels), combine_tags(pred_labels)), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86%-89% - це значне покращення порівняно з першим варіантом, але для POS-таггера досить поганий результат. На корпусі WSJ навіть бейзлайнові класифікатори дають точність 92%, а state-of-the-art - 97%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
